{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# from shopee_challenge_customlib import get_attributes_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_info_train = pd.read_csv('./dataset/mobile_data_info_train_competition.csv')\n",
    "mobile_info_test = pd.read_csv('./dataset/mobile_data_info_val_competition.csv')\n",
    "mobile_profile = pd.read_json('./dataset/mobile_profile_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path_ubuntu = '/media/terence/hd_storage/sam/shopee-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes_lookup(df):\n",
    "    \n",
    "    attributes_lookup = {}\n",
    "    num_total_categories = 0\n",
    "    \n",
    "    for attribute in df.columns:\n",
    "        num_categories_per_attribute = 0\n",
    "        \n",
    "        cat_keys = df[attribute][df[attribute].notnull()].values\n",
    "        cat_values = df[attribute][df[attribute].notnull()].index\n",
    "        attributes_lookup[attribute] = dict(zip(cat_keys, cat_values))\n",
    "        \n",
    "        num_total_categories += len(cat_keys)\n",
    "        \n",
    "    if num_total_categories > len(df):\n",
    "        print('1 profile type falls under more than attribute. Manually check profiles.')\n",
    "        print('No. of df rows: ', len(df))\n",
    "        print('No. of categories: ', num_total_categories)\n",
    "    elif num_total_categories < len(df):\n",
    "        print('Some rows in original dataframe might be unaccounted for or entirely composed of NaNs. Check input df.')\n",
    "        print('No. of df rows: ', len(df))\n",
    "        print('No. of categories: ', num_total_categories)\n",
    "    elif num_total_categories == len(df):\n",
    "        print('All good. Number of lookup categories == rows in input df.')\n",
    "        \n",
    "    return attributes_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 profile type falls under more than attribute. Manually check profiles.\n",
      "No. of df rows:  2433\n",
      "No. of categories:  2443\n"
     ]
    }
   ],
   "source": [
    "mobile_lookup = get_attributes_lookup(mobile_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_lookup['Color Family'][26.0] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors(n):    \n",
    "    return set(reduce(list.__add__, \n",
    "                ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df_for_image(df, attribute=None):\n",
    "    \n",
    "    try: \n",
    "        transformed = df[['itemid', 'image_path', attribute]].copy()\n",
    "        #change this to regex later\n",
    "        transformed['image_path'] = transformed['image_path'].apply(lambda x: \n",
    "                                                                    x[len('mobile_image/'):])\n",
    "        \n",
    "        nan_label = df[attribute].max() + 1\n",
    "        transformed[attribute].fillna(nan_label, inplace=True)\n",
    "        \n",
    "        ohe = pd.DataFrame(keras.utils.to_categorical(transformed[attribute]))\n",
    "        \n",
    "        transformed = pd.concat([transformed, ohe], axis=1)\n",
    "        \n",
    "    except KeyError: \n",
    "        transformed = df[['itemid', 'image_path']].copy()\n",
    "        #change this to regex later\n",
    "        transformed['image_path'] = transformed['image_path'].apply(lambda x: \n",
    "                                                                    x[len('mobile_image/'):])\n",
    "        \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually train test split\n",
    "def train_val_test_split(vertical_df_train, vertical_df_test, attribute, test_size=0.2):\n",
    "    \n",
    "    test_df = preprocess_df_for_image(vertical_df_test)\n",
    "    attr_df = preprocess_df_for_image(vertical_df_train, attribute)\n",
    "    \n",
    "    # to use stratified shuffle split, must get rid of train labels with only one instance\n",
    "    sss = ShuffleSplit(n_splits=1, test_size=test_size)\n",
    "    \n",
    "    for train_index, val_index in sss.split(np.zeros(len(vertical_df_train)), \n",
    "                                            vertical_df_train[attribute]):\n",
    "        train_df = attr_df.iloc[train_index].reset_index() # must reset index else generator will throw error\n",
    "        val_df = attr_df.iloc[val_index].reset_index()\n",
    "        \n",
    "    print('Train Rows: ', len(train_df))\n",
    "    print('Val Rows: ', len(val_df))\n",
    "    print('Test Rows: ', len(test_df))\n",
    "    \n",
    "    train_prp = train_df[attribute].value_counts()/len(train_df)\n",
    "    val_prp = val_df[attribute].value_counts()/len(val_df)\n",
    "    \n",
    "    prp_comparison = pd.concat([train_prp, val_prp], axis=1, sort=False)\n",
    "    prp_comparison.columns = ['Train', 'Val']\n",
    "    print(prp_comparison)\n",
    " \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Rows:  128264\n",
      "Val Rows:  32066\n",
      "Test Rows:  40417\n",
      "         Train       Val\n",
      "0.0   0.106616  0.108744\n",
      "1.0   0.001965  0.002339\n",
      "2.0   0.004272  0.003836\n",
      "3.0   0.000008 NaN      \n",
      "4.0   0.024489  0.024200\n",
      "6.0   0.005185  0.005707\n",
      "7.0   0.002401  0.002370\n",
      "10.0  0.233199  0.231990\n",
      "11.0  0.001208  0.001279\n",
      "12.0  0.048884  0.050303\n",
      "13.0  0.043761  0.043223\n",
      "14.0  0.002386  0.002089\n",
      "16.0  0.000405  0.000343\n",
      "17.0  0.000133  0.000187\n",
      "18.0  0.000507  0.000437\n",
      "19.0  0.034983  0.034585\n",
      "20.0  0.014821  0.014283\n",
      "22.0  0.000031 NaN      \n",
      "23.0  0.000008 NaN      \n",
      "24.0  0.000008 NaN      \n",
      "25.0  0.003703  0.003711\n",
      "26.0  0.471029  0.470374\n"
     ]
    }
   ],
   "source": [
    "colorfam_img_train, colorfam_img_val, colorfam_img_test = train_val_test_split(mobile_info_train, \n",
    "                                                                               mobile_info_test, \n",
    "                                                                               'Color Family', \n",
    "                                                                               0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>itemid</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Color Family</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112145</td>\n",
       "      <td>1296556499</td>\n",
       "      <td>78bfceb713a18c94595f84f5bb19feda.jpg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50663</td>\n",
       "      <td>975294142</td>\n",
       "      <td>889fbb6744207a303756ee8b03ab8f44.jpg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      itemid                            image_path  Color Family  \\\n",
       "0  112145  1296556499  78bfceb713a18c94595f84f5bb19feda.jpg  26.0           \n",
       "1  50663   975294142   889fbb6744207a303756ee8b03ab8f44.jpg  10.0           \n",
       "\n",
       "     0    1    2    3    4    5 ...    17   18   19   20   21   22   23   24  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    25   26  \n",
       "0  0.0  1.0  \n",
       "1  0.0  0.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorfam_img_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 32066, 64132, 4, 16033, 128264, 8}\n",
      "{1, 32066, 2, 16033}\n",
      "{1, 13, 3109, 40417}\n"
     ]
    }
   ],
   "source": [
    "print(factors(len(colorfam_img_train)))\n",
    "print(factors(len(colorfam_img_val)))\n",
    "print(factors(len(colorfam_img_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "VAL_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 13\n",
    "TARGET_SIZE = (8, 8)\n",
    "\n",
    "input_shape = (TARGET_SIZE[0], TARGET_SIZE[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128264 images.\n",
      "Found 32066 images.\n",
      "Found 40417 images.\n"
     ]
    }
   ],
   "source": [
    "# manual split implementation - throws an error\n",
    "# maybe must one hot encode before manually splitting\n",
    "# for other way - can i get the validation set indices?\n",
    "colorfam_train_generator = train_datagen.flow_from_dataframe(dataframe = colorfam_img_train, \n",
    "                                                             directory = './dataset/images/mobile_image',\n",
    "                                                             x_col = 'image_path', \n",
    "                                                             y_col = colorfam_img_train.columns[4:],\n",
    "                                                             shuffle = True,\n",
    "                                                             class_mode = 'other',\n",
    "                                                             target_size = TARGET_SIZE, \n",
    "                                                             batch_size = TRAIN_BATCH_SIZE)\n",
    "\n",
    "colorfam_val_generator = test_datagen.flow_from_dataframe(dataframe = colorfam_img_val, \n",
    "                                                           directory = './dataset/images/mobile_image',\n",
    "                                                           x_col = 'image_path', \n",
    "                                                           y_col = colorfam_img_train.columns[4:], \n",
    "                                                           shuffle = False,\n",
    "                                                           class_mode = 'other',\n",
    "                                                           target_size = TARGET_SIZE, \n",
    "                                                           batch_size = VAL_BATCH_SIZE)\n",
    "\n",
    "colorfam_test_generator = test_datagen.flow_from_dataframe(dataframe = colorfam_img_test,\n",
    "                                                           directory = './dataset/images/mobile_image',\n",
    "                                                           x_col = 'image_path',\n",
    "                                                           y_col = None,\n",
    "                                                           class_mode = None,\n",
    "                                                           shuffle=False,\n",
    "                                                           target_size = TARGET_SIZE,\n",
    "                                                           batch_size = TEST_BATCH_SIZE)\n",
    "\n",
    "# for test generator, batch size has to be exactly divisible by num of samples \n",
    "# so that we don't miss out on any predictions\n",
    "# if in doubt, put batch_size=1, but it'll be super slow\n",
    "# always set Shuffle to False for Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128173 images belonging to 22 classes.\n",
      "Found 32157 images belonging to 22 classes.\n",
      "Found 40417 images.\n"
     ]
    }
   ],
   "source": [
    "# # keras validation_split implementation\n",
    "\n",
    "# colorfam_img_train = preprocess_df_for_image(mobile_info_train, 'Color Family')\n",
    "# colorfam_img_test = preprocess_df_for_image(mobile_info_val)\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1/255, \n",
    "#                                    shear_range = 0.2, \n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True,\n",
    "#                                    validation_split = 0.2)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# colorfam_train_generator = train_datagen.flow_from_dataframe(dataframe = colorfam_img_train, \n",
    "#                                                              directory = './dataset/images/mobile_image',\n",
    "#                                                              x_col = 'image_path', \n",
    "#                                                              y_col = 'Color Family',\n",
    "#                                                              shuffle = True,\n",
    "#                                                              subset='training',\n",
    "#                                                              class_mode = 'categorical',\n",
    "#                                                              target_size = TARGET_SIZE, \n",
    "#                                                              batch_size = TRAIN_BATCH_SIZE)\n",
    "\n",
    "# colorfam_val_generator = train_datagen.flow_from_dataframe(dataframe = colorfam_img_train, \n",
    "#                                                            directory = './dataset/images/mobile_image',\n",
    "#                                                            x_col = 'image_path', \n",
    "#                                                            y_col = 'Color Family',\n",
    "#                                                            subset = 'validation',\n",
    "#                                                            shuffle = True,\n",
    "#                                                            class_mode = 'categorical',\n",
    "#                                                            target_size = TARGET_SIZE, \n",
    "#                                                            batch_size = VAL_BATCH_SIZE)\n",
    "\n",
    "# colorfam_test_generator = test_datagen.flow_from_dataframe(dataframe = colorfam_img_test,\n",
    "#                                                            directory = './dataset/images/mobile_image',\n",
    "#                                                            x_col = 'image_path',\n",
    "#                                                            y_col = None,\n",
    "#                                                            class_mode = None,\n",
    "#                                                            shuffle=False,\n",
    "#                                                            target_size = TARGET_SIZE,\n",
    "#                                                            batch_size = TEST_BATCH_SIZE)\n",
    "\n",
    "# # for test generator, batch size has to be exactly divisible by num of samples \n",
    "# # so that we don't miss out on any predictions\n",
    "# # if in doubt, put batch_size=1, but it'll be super slow\n",
    "# # always set Shuffle to False for Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert colorfam_train_generator.samples + colorfam_val_generator.samples == mobile_info_train.shape[0]\n",
    "assert colorfam_test_generator.samples == mobile_info_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 32)          896       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 27)                1755      \n",
      "=================================================================\n",
      "Total params: 88,059\n",
      "Trainable params: 88,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=input_shape, activation='relu'))\n",
    "classifier.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "classifier.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.6))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "classifier.add(Dense(units=27, activation='softmax'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2005/2005 [==============================] - 583s 291ms/step - loss: 1.6728 - acc: 0.4646 - val_loss: 1.5953 - val_acc: 0.4694\n",
      "Epoch 2/2\n",
      "2005/2005 [==============================] - 584s 291ms/step - loss: 1.6106 - acc: 0.4711 - val_loss: 1.5971 - val_acc: 0.4714\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(colorfam_train_generator, \n",
    "                                   steps_per_epoch=colorfam_train_generator.samples//TRAIN_BATCH_SIZE + 1,\n",
    "                                   epochs=2,\n",
    "                                   validation_data=colorfam_val_generator,\n",
    "                                   validation_steps=colorfam_val_generator.samples//TRAIN_BATCH_SIZE + 1, \n",
    "                                   workers=2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_weights('mobile_colorfam_weights_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3109/3109 [==============================] - 302s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "# need to reset the test_generator before whenever you call the predict_generator\n",
    "# If not, will get outputs in a weird order\n",
    "colorfam_test_generator.reset()\n",
    "actual_preds = classifier.predict_generator(colorfam_test_generator, \n",
    "                                            colorfam_test_generator.samples//TEST_BATCH_SIZE, \n",
    "                                            workers=2, \n",
    "                                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40417, 27)\n"
     ]
    }
   ],
   "source": [
    "print(actual_preds.shape)\n",
    "assert actual_preds.shape[0] == len(mobile_info_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32066 images.\n",
      "502/502 [==============================] - 235s 467ms/step\n"
     ]
    }
   ],
   "source": [
    "# check if can get colorfam_val_generator indices\n",
    "# or is it just last 20%\n",
    "colorfam_val_generator = test_datagen.flow_from_dataframe(dataframe = colorfam_img_val, \n",
    "                                                           directory = './dataset/images/mobile_image',\n",
    "                                                           x_col = 'image_path', \n",
    "                                                           y_col = None, \n",
    "                                                           shuffle = False,\n",
    "                                                           class_mode = None,\n",
    "                                                           target_size = TARGET_SIZE, \n",
    "                                                           batch_size = VAL_BATCH_SIZE)\n",
    "\n",
    "\n",
    "colorfam_val_generator.reset()\n",
    "val_preds = classifier.predict_generator(colorfam_val_generator,\n",
    "                                         colorfam_val_generator.samples//VAL_BATCH_SIZE + 1, \n",
    "                                         verbose=1, \n",
    "                                         workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32066, 27)\n"
     ]
    }
   ],
   "source": [
    "print(val_preds.shape)\n",
    "assert val_preds.shape[0] == len(colorfam_img_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get Preds ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels from the 2 highest probabilities\n",
    "\n",
    "def get_prediction_labels(predict_probas, k):\n",
    "    return np.argsort(predict_probas)[-1:-(k+1):-1]\n",
    "\n",
    "def get_all_preds(predict_probas, k):\n",
    "    \n",
    "    all_labels = []\n",
    "    \n",
    "    for proba in predict_probas:    \n",
    "        first, second = get_prediction_labels(proba, k)\n",
    "        label = '{} {}'.format(first, second)\n",
    "        all_labels.append(label)\n",
    "        \n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/pestipeti/explanation-of-map5-scoring-metric\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 2 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\" \n",
    "    label = str(int(label))\n",
    "    predictions = predictions.split(' ') # own code\n",
    "    \n",
    "    try:\n",
    "        return 1 / (predictions[:2].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def map_per_set(labels, predictions):\n",
    "    \"\"\"Computes the average over multiple images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list\n",
    "             A list of the true labels. (Only one true label per images allowed!)\n",
    "    predictions : list of list\n",
    "             A list of predicted elements (order does matter, 2 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    return np.mean([map_per_image(l, p) for l,p in zip(labels, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_check = colorfam_img_val[['index', 'itemid', 'image_path', 'Color Family']].copy()\n",
    "val_preds_check['preds'] = get_all_preds(val_preds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_results(df, row_num):\n",
    "    \n",
    "    image_path = df.iloc[row_num]['image_path']\n",
    "    actual_label = df.iloc[row_num]['Color Family']\n",
    "    predicted_label_1, predicted_label_2 = [float(pred) for pred in df.iloc[row_num]['preds'].split(' ')]\n",
    "    \n",
    "    print('Predicted Attribute: {} ({})'.format(predicted_label_1, mobile_lookup['Color Family'][predicted_label_1]))\n",
    "    print('Predicted Attribute 2: {} ({})'.format(predicted_label_2, mobile_lookup['Color Family'][predicted_label_2]))\n",
    "    print('Actual Label: {} ({})'.format(actual_label, mobile_lookup['Color Family'][actual_label]))\n",
    "    \n",
    "    display(image.load_img('./dataset/images/mobile_image/'+image_path, target_size=(300,300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Attribute: 26.0 (NaN)\n",
      "Predicted Attribute 2: 10.0 (black)\n",
      "Actual Label: 26.0 (NaN)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300 at 0x120260AC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_results(val_preds_check, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0    0.470374\n",
       "10.0    0.231990\n",
       "0.0     0.108744\n",
       "12.0    0.050303\n",
       "13.0    0.043223\n",
       "19.0    0.034585\n",
       "4.0     0.024200\n",
       "20.0    0.014283\n",
       "6.0     0.005707\n",
       "2.0     0.003836\n",
       "25.0    0.003711\n",
       "7.0     0.002370\n",
       "1.0     0.002339\n",
       "14.0    0.002089\n",
       "11.0    0.001279\n",
       "18.0    0.000437\n",
       "16.0    0.000343\n",
       "17.0    0.000187\n",
       "Name: Color Family, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "val_preds_check['Color Family'].value_counts()/len(val_preds_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gold'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_lookup['Color Family'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to evaluate MAP@2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>itemid</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Color Family</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>67578</td>\n",
       "      <td>1058601793</td>\n",
       "      <td>080dab621993dbd146a8792002a51f68.jpg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>38336</td>\n",
       "      <td>607058297</td>\n",
       "      <td>f4f969382f30e31f04a97f5ace86df55.jpg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15040</th>\n",
       "      <td>23522</td>\n",
       "      <td>1283240990</td>\n",
       "      <td>8d58226fe68360fdff9f405b9df0f66d.jpg</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13396</th>\n",
       "      <td>153043</td>\n",
       "      <td>1287583541</td>\n",
       "      <td>ec654c0d0750b935e84a7e9508243fd2.jpg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>118390</td>\n",
       "      <td>1693180232</td>\n",
       "      <td>9ed760fdcd5e19ce63c3fcd208994888.jpg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index      itemid                            image_path  Color Family  \\\n",
       "15913  67578   1058601793  080dab621993dbd146a8792002a51f68.jpg  26.0           \n",
       "4214   38336   607058297   f4f969382f30e31f04a97f5ace86df55.jpg  10.0           \n",
       "15040  23522   1283240990  8d58226fe68360fdff9f405b9df0f66d.jpg  12.0           \n",
       "13396  153043  1287583541  ec654c0d0750b935e84a7e9508243fd2.jpg  26.0           \n",
       "1347   118390  1693180232  9ed760fdcd5e19ce63c3fcd208994888.jpg  26.0           \n",
       "\n",
       "       preds  \n",
       "15913  26 10  \n",
       "4214   26 10  \n",
       "15040  26 0   \n",
       "13396  26 10  \n",
       "1347   26 10  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_check.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_per_image(val_preds_check.loc[4214, 'Color Family'], val_preds_check.loc[4214, 'preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653807771471341"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_per_set(val_preds_check['Color Family'], val_preds_check['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # taken from https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "# def apk(actual, predicted, k=10):\n",
    "#     \"\"\"\n",
    "#     Computes the average precision at k.\n",
    "#     This function computes the average prescision at k between two lists of\n",
    "#     items.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     actual : list\n",
    "#              A list of elements that are to be predicted (order doesn't matter)\n",
    "#     predicted : list\n",
    "#                 A list of predicted elements (order does matter)\n",
    "#     k : int, optional\n",
    "#         The maximum number of predicted elements\n",
    "#     Returns\n",
    "#     -------\n",
    "#     score : double\n",
    "#             The average precision at k over the input lists\n",
    "#     \"\"\"\n",
    "#     if len(predicted)>k:\n",
    "#         predicted = predicted[:k]\n",
    "\n",
    "#     score = 0.0\n",
    "#     num_hits = 0.0\n",
    "\n",
    "#     for i,p in enumerate(predicted):\n",
    "#         if p in actual and p not in predicted[:i]:\n",
    "#             num_hits += 1.0\n",
    "#             score += num_hits / (i+1.0)\n",
    "\n",
    "#     if not actual:\n",
    "#         return 0.0\n",
    "\n",
    "#     return score / min(len(actual), k)\n",
    "\n",
    "# def mapk(actual, predicted, k=10):\n",
    "#     \"\"\"\n",
    "#     Computes the mean average precision at k.\n",
    "#     This function computes the mean average prescision at k between two lists\n",
    "#     of lists of items.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     actual : list\n",
    "#              A list of lists of elements that are to be predicted \n",
    "#              (order doesn't matter in the lists)\n",
    "#     predicted : list\n",
    "#                 A list of lists of predicted elements\n",
    "#                 (order matters in the lists)\n",
    "#     k : int, optional\n",
    "#         The maximum number of predicted elements\n",
    "#     Returns\n",
    "#     -------\n",
    "#     score : double\n",
    "#             The mean average precision at k over the input lists\n",
    "#     \"\"\"\n",
    "#     return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
